{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "            builder. \\\n",
    "            master('local'). \\\n",
    "            appName(\"practice\"). \\\n",
    "            getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25b24c765c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = spark.read.json(r\"C:\\Users\\Kshitij kadu\\Desktop\\retail\\orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read.json(r\"C:\\Users\\Kshitij kadu\\Desktop\\retail\\customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12435"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = order_df.join(broadcast(customer_df),order_df.order_customer_id == customer_df.customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [order_customer_id#7L], [customer_id#34L], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(order_customer_id#7L)\n",
      ":  +- FileScan json [order_customer_id#7L,order_date#8,order_id#9L,order_status#10] Batched: false, DataFilters: [isnotnull(order_customer_id#7L)], Format: JSON, Location: InMemoryFileIndex[file:/C:/Users/Kshitij kadu/Desktop/retail/orders], PartitionFilters: [], PushedFilters: [IsNotNull(order_customer_id)], ReadSchema: struct<order_customer_id:bigint,order_date:string,order_id:bigint,order_status:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[3, bigint, false]),false), [id=#146]\n",
      "   +- *(1) Filter isnotnull(customer_id#34L)\n",
      "      +- FileScan json [customer_city#31,customer_email#32,customer_fname#33,customer_id#34L,customer_lname#35,customer_password#36,customer_state#37,customer_street#38,customer_zipcode#39] Batched: false, DataFilters: [isnotnull(customer_id#34L)], Format: JSON, Location: InMemoryFileIndex[file:/C:/Users/Kshitij kadu/Desktop/retail/customers], PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<customer_city:string,customer_email:string,customer_fname:string,customer_id:bigint,custom...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repartitioning and coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartitioning - It is use to increase the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalesce - it is use to decrease the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method json in module pyspark.sql.readwriter:\n",
      "\n",
      "json(path, mode=None, compression=None, dateFormat=None, timestampFormat=None, lineSep=None, encoding=None, ignoreNullFields=None) method of pyspark.sql.readwriter.DataFrameWriter instance\n",
      "    Saves the content of the :class:`DataFrame` in JSON format\n",
      "    (`JSON Lines text format or newline-delimited JSON <http://jsonlines.org/>`_) at the\n",
      "    specified path.\n",
      "    \n",
      "    .. versionadded:: 1.4.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : str\n",
      "        the path in any Hadoop supported file system\n",
      "    mode : str, optional\n",
      "        specifies the behavior of the save operation when data already exists.\n",
      "    \n",
      "        * ``append``: Append contents of this :class:`DataFrame` to existing data.\n",
      "        * ``overwrite``: Overwrite existing data.\n",
      "        * ``ignore``: Silently ignore this operation if data already exists.\n",
      "        * ``error`` or ``errorifexists`` (default case): Throw an exception if data already                 exists.\n",
      "    compression : str, optional\n",
      "        compression codec to use when saving to file. This can be one of the\n",
      "        known case-insensitive shorten names (none, bzip2, gzip, lz4,\n",
      "        snappy and deflate).\n",
      "    dateFormat : str, optional\n",
      "        sets the string that indicates a date format. Custom date formats\n",
      "        follow the formats at\n",
      "        `datetime pattern <https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html>`_.  # noqa\n",
      "        This applies to date type. If None is set, it uses the\n",
      "        default value, ``yyyy-MM-dd``.\n",
      "    timestampFormat : str, optional\n",
      "        sets the string that indicates a timestamp format.\n",
      "        Custom date formats follow the formats at\n",
      "        `datetime pattern <https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html>`_.  # noqa\n",
      "        This applies to timestamp type. If None is set, it uses the\n",
      "        default value, ``yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX]``.\n",
      "    encoding : str, optional\n",
      "        specifies encoding (charset) of saved json files. If None is set,\n",
      "        the default UTF-8 charset will be used.\n",
      "    lineSep : str, optional\n",
      "        defines the line separator that should be used for writing. If None is\n",
      "        set, it uses the default value, ``\\n``.\n",
      "    ignoreNullFields : str or bool, optional\n",
      "        Whether to ignore null fields when generating JSON objects.\n",
      "        If None is set, it uses the default value, ``true``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.write.json(os.path.join(tempfile.mkdtemp(), 'data'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_join.write.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.repartition(4).write.json(r\"C:\\Users\\Kshitij kadu\\Desktop\\retail\\write\\temp_repartition\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to increase the amount of partiton using coalesce - It will not increase the\n",
    "   partition and It will not throw an exception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.coalesce(4).write.json(r\"C:\\Users\\Kshitij kadu\\Desktop\\retail\\write\\temp_coalesce\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark transformations - \n",
    "\n",
    "Spark Transformation is a function that produces new RDD from\n",
    "the existing RDDs. It takes RDD as input and produces one or more RDD as output. \n",
    "Each time it creates new RDD when we apply any transformation\n",
    "\n",
    "transformation is an lazy evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.read.csv(r'C:\\Users\\Kshitij kadu\\Desktop\\sample_data\\Records.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Emp ID: integer (nullable = true)\n",
      " |-- Name Prefix: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Middle Initial: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- E Mail: string (nullable = true)\n",
      " |-- Father's Name: string (nullable = true)\n",
      " |-- Mother's Name: string (nullable = true)\n",
      " |-- Mother's Maiden Name: string (nullable = true)\n",
      " |-- Date of Birth: string (nullable = true)\n",
      " |-- Time of Birth: string (nullable = true)\n",
      " |-- Age in Yrs.: double (nullable = true)\n",
      " |-- Weight in Kgs.: integer (nullable = true)\n",
      " |-- Date of Joining: string (nullable = true)\n",
      " |-- Quarter of Joining: string (nullable = true)\n",
      " |-- Half of Joining: string (nullable = true)\n",
      " |-- Year of Joining: integer (nullable = true)\n",
      " |-- Month of Joining: integer (nullable = true)\n",
      " |-- Month Name of Joining: string (nullable = true)\n",
      " |-- Short Month: string (nullable = true)\n",
      " |-- Day of Joining: integer (nullable = true)\n",
      " |-- DOW of Joining: string (nullable = true)\n",
      " |-- Short DOW: string (nullable = true)\n",
      " |-- Age in Company (Years): double (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Last % Hike: string (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Phone No. : string (nullable = true)\n",
      " |-- Place Name: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zip: integer (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- User Name: string (nullable = true)\n",
      " |-- Password: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = emp_df.select(\"Emp id\",\"First Name\",\\\n",
    "               \"last Name\", \"Gender\", \"E Mail\",\"Date of Joining\",\"Salary\",\"County\",\"City\", \"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+--------------------+---------------+------+------------+---------------+-----+\n",
      "|Emp id|First Name|last Name|Gender|              E Mail|Date of Joining|Salary|      County|           City|State|\n",
      "+------+----------+---------+------+--------------------+---------------+------+------------+---------------+-----+\n",
      "|198429|  Serafina|Bumgarner|     F|serafina.bumgarne...|       2/1/2008| 69294|  Chautauqua|         Clymer|   NY|\n",
      "|178566|  Juliette|     Rojo|     F|juliette.rojo@yah...|       6/4/2011|193912|  Montgomery|       Glenside|   PA|\n",
      "|647173|     Milan| Krawczyk|     M|milan.krawczyk@ho...|      1/19/2012|123681|Anne Arundel|  Gibson Island|   MD|\n",
      "|847634|     Elmer|    Jason|     M|elmer.jason@yahoo...|      5/28/2017| 93504|  Washington|        Mendota|   VA|\n",
      "|260736|     Zelda|   Forest|     F|zelda.forest@ibm.com|      1/28/2014|176642| Schenectady|    Schenectady|   NY|\n",
      "|811306|     Rhett|      Wan|     M|rhett.wan@hotmail...|      1/21/2009| 59406|      Fresno|          Selma|   CA|\n",
      "|956633|       Hal|   Farrow|     M|  hal.farrow@cox.net|      2/25/1991|164580|  Stanislaus|        Modesto|   CA|\n",
      "|629539|       Del|Fernandez|     M|del.fernandez@hot...|       4/7/2016|138662|     Portage|           Kent|   OH|\n",
      "|784160|     Corey|  Jackman|     M|corey.jackman@gma...|      6/29/1984| 57616|     Jamaica|        Jamaica|   NY|\n",
      "|744723|      Bibi|  Paddock|     F|bibi.paddock@yaho...|      11/2/2016| 87148|     Overton|        Rickman|   TN|\n",
      "|423093|      Eric|  Manning|     M|eric.manning@yaho...|     10/28/2002|149363|     Fayette|       Clermont|   IA|\n",
      "|207808|   Renetta|   Hafner|     F|renetta.hafner@ao...|      8/22/1998|180289|     Broward|Fort Lauderdale|   FL|\n",
      "|338634|       Paz|  Pearman|     F|paz.pearman@gmail...|      5/25/1982|144804|     Clayton|     Garnavillo|   IA|\n",
      "|324573|    Ardath|   Forman|     F|ardath.forman@gma...|     10/16/2009|189373|      Clarke|         Athens|   GA|\n",
      "|953724|     Nanci|   Osorio|     F|nanci.osorio@hotm...|      11/7/2003| 71321|     Grafton|        Lincoln|   NH|\n",
      "|138700|  Maricela|   Simard|     F|maricela.simard@g...|      9/25/2016| 88513|     Sampson|         Ingold|   NC|\n",
      "|644265|   Avelina|   Stoner|     F|avelina.stoner@ex...|     11/30/2010|157826|Westmoreland|         Salina|   PA|\n",
      "|223871| Christene| Mattison|     F|christene.mattiso...|      9/13/2015|177224|      Jasper|           Alba|   MO|\n",
      "|807262|    Stefan|    Maeda|     M|stefan.maeda@yaho...|      11/5/2011| 67028| St. Tammany|        Slidell|   LA|\n",
      "|368234|   Gillian|   Winter|     F|gillian.winter@gm...|     11/28/1984|103619|       Otero|     Alamogordo|   NM|\n",
      "+------+----------+---------+------+--------------------+---------------+------+------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+------+--------------------+---------------+------+---------------+-------------+-----+\n",
      "|Emp id|First Name|  last Name|Gender|              E Mail|Date of Joining|Salary|         County|         City|State|\n",
      "+------+----------+-----------+------+--------------------+---------------+------+---------------+-------------+-----+\n",
      "|647173|     Milan|   Krawczyk|     M|milan.krawczyk@ho...|      1/19/2012|123681|   Anne Arundel|Gibson Island|   MD|\n",
      "|847634|     Elmer|      Jason|     M|elmer.jason@yahoo...|      5/28/2017| 93504|     Washington|      Mendota|   VA|\n",
      "|811306|     Rhett|        Wan|     M|rhett.wan@hotmail...|      1/21/2009| 59406|         Fresno|        Selma|   CA|\n",
      "|956633|       Hal|     Farrow|     M|  hal.farrow@cox.net|      2/25/1991|164580|     Stanislaus|      Modesto|   CA|\n",
      "|629539|       Del|  Fernandez|     M|del.fernandez@hot...|       4/7/2016|138662|        Portage|         Kent|   OH|\n",
      "|784160|     Corey|    Jackman|     M|corey.jackman@gma...|      6/29/1984| 57616|        Jamaica|      Jamaica|   NY|\n",
      "|423093|      Eric|    Manning|     M|eric.manning@yaho...|     10/28/2002|149363|        Fayette|     Clermont|   IA|\n",
      "|807262|    Stefan|      Maeda|     M|stefan.maeda@yaho...|      11/5/2011| 67028|    St. Tammany|      Slidell|   LA|\n",
      "|807442|        Ed|    Ferrari|     M|ed.ferrari@gmail.com|      2/15/2015|145831|          Ector|   Gardendale|   TX|\n",
      "|496781|  Jonathan|       Rosa|     M|jonathan.rosa@gma...|      7/23/2010|198838|        Fairfax| Falls Church|   VA|\n",
      "|301629|     Ruben|   Weissman|     M|ruben.weissman@gm...|       1/3/2017| 48543|         Bergen| Elmwood Park|   NJ|\n",
      "|872750|   Johnnie|     Ibarra|     M|johnnie.ibarra@ao...|      4/14/2013|181385|      San Diego|    San Diego|   CA|\n",
      "|813428|   Emerson|      Sands|     M|emerson.sands@gma...|       1/1/2015|106048|           Cass|     Dowagiac|   MI|\n",
      "|380228|   Oswaldo|       Dodd|     M|oswaldo.dodd@gmai...|     11/14/1998| 92047|     Washington|     Harrison|   GA|\n",
      "|613551|       Jay|    Shields|     M|jay.shields@gmail...|      8/26/2013|167893|      Jefferson|       Denver|   CO|\n",
      "|147663|  Douglass|   Corrigan|     M|douglass.corrigan...|      2/19/2015| 86718|           Kane|Saint Charles|   IL|\n",
      "|794524|    Armand|Fortenberry|     M|armand.fortenberr...|      2/17/2017|184287|         Greene|      Windham|   NY|\n",
      "|392234|     Monty|       Hail|     M|monty.hail@gmail.com|     10/30/1983| 89286|        Hampden|  Springfield|   MA|\n",
      "|529020|   Bernard|   Bradshaw|     M|bernard.bradshaw@...|      3/31/2002| 98634|Prince George's|    Greenbelt|   MD|\n",
      "|269950|      Seth|   Bilodeau|     M|seth.bilodeau@bel...|       7/6/2002|164287|         Benzie|     Lake Ann|   MI|\n",
      "+------+----------+-----------+------+--------------------+---------------+------+---------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.filter(\"Gender = 'M' and Salary > 20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|State|count|\n",
      "+-----+-----+\n",
      "|   SC|  132|\n",
      "|   AZ|  145|\n",
      "|   LA|  168|\n",
      "|   MN|  253|\n",
      "|   NJ|  189|\n",
      "|   DC|   66|\n",
      "|   OR|   99|\n",
      "|   VA|  303|\n",
      "|   RI|   22|\n",
      "|   KY|  260|\n",
      "|   WY|   41|\n",
      "|   NH|   59|\n",
      "|   MI|  292|\n",
      "|   NV|   49|\n",
      "|   WI|  218|\n",
      "|   ID|   84|\n",
      "|   CA|  618|\n",
      "|   CT|  111|\n",
      "|   NE|  143|\n",
      "|   MT|   99|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy(\"State\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Emp id: int, First Name: string, last Name: string, Gender: string, E Mail: string, Date of Joining: string, Salary: int, County: string, City: string, State: string]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Broadcast join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = order_df.join(broadcast(customer_df),order_df.order_customer_id == customer_df.customer_id).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "|order_customer_id|          order_date|order_id|   order_status|customer_city|customer_email|customer_fname|customer_id|customer_lname|customer_password|customer_state|     customer_street|customer_zipcode|\n",
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "|            11599|2013-07-25 00:00:...|       1|         CLOSED|      Hickory|     XXXXXXXXX|          Mary|      11599|        Malone|        XXXXXXXXX|            NC|8708 Indian Horse...|           28601|\n",
      "|              256|2013-07-25 00:00:...|       2|PENDING_PAYMENT|      Chicago|     XXXXXXXXX|         David|        256|     Rodriguez|        XXXXXXXXX|            IL|7605 Tawny Horse ...|           60625|\n",
      "|            12111|2013-07-25 00:00:...|       3|       COMPLETE|   Santa Cruz|     XXXXXXXXX|         Amber|      12111|        Franco|        XXXXXXXXX|            CA|8766 Clear Prairi...|           95060|\n",
      "|             8827|2013-07-25 00:00:...|       4|         CLOSED|  San Antonio|     XXXXXXXXX|         Brian|       8827|        Wilson|        XXXXXXXXX|            TX|   8396 High Corners|           78240|\n",
      "|            11318|2013-07-25 00:00:...|       5|       COMPLETE|       Caguas|     XXXXXXXXX|          Mary|      11318|         Henry|        XXXXXXXXX|            PR|3047 Silent Ember...|           00725|\n",
      "|             7130|2013-07-25 00:00:...|       6|       COMPLETE|     Brooklyn|     XXXXXXXXX|         Alice|       7130|         Smith|        XXXXXXXXX|            NY|      8852 Iron Port|           11237|\n",
      "|             4530|2013-07-25 00:00:...|       7|       COMPLETE|        Miami|     XXXXXXXXX|          Mary|       4530|         Smith|        XXXXXXXXX|            FL|1073 Green Leaf G...|           33161|\n",
      "|             2911|2013-07-25 00:00:...|       8|     PROCESSING|       Caguas|     XXXXXXXXX|          Mary|       2911|         Smith|        XXXXXXXXX|            PR|9166 Golden Necta...|           00725|\n",
      "|             5657|2013-07-25 00:00:...|       9|PENDING_PAYMENT|     Lakewood|     XXXXXXXXX|          Mary|       5657|         James|        XXXXXXXXX|            OH|  1389 Dusty Circuit|           44107|\n",
      "|             5648|2013-07-25 00:00:...|      10|PENDING_PAYMENT|      Memphis|     XXXXXXXXX|        Joshua|       5648|         Smith|        XXXXXXXXX|            TN|864 Iron Spring S...|           38111|\n",
      "|              918|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|       Caguas|     XXXXXXXXX|        Nathan|        918|         Smith|        XXXXXXXXX|            PR|    9627 Honey Trail|           00725|\n",
      "|             1837|2013-07-25 00:00:...|      12|         CLOSED|       Caguas|     XXXXXXXXX|          Mary|       1837|          Vega|        XXXXXXXXX|            PR|  4312 Bright Corner|           00725|\n",
      "|             9149|2013-07-25 00:00:...|      13|PENDING_PAYMENT|    Santa Ana|     XXXXXXXXX|        Ronald|       9149|     Whitehead|        XXXXXXXXX|            CA|6789 Round Robin ...|           92705|\n",
      "|             9842|2013-07-25 00:00:...|      14|     PROCESSING|       Caguas|     XXXXXXXXX|          Mary|       9842|         Smith|        XXXXXXXXX|            PR|454 Lazy Branch F...|           00725|\n",
      "|             2568|2013-07-25 00:00:...|      15|       COMPLETE|      Memphis|     XXXXXXXXX|         Maria|       2568|         Smith|        XXXXXXXXX|            TN|   3544 Fallen Mount|           38127|\n",
      "|             7276|2013-07-25 00:00:...|      16|PENDING_PAYMENT|       Caguas|     XXXXXXXXX|        Pamela|       7276|         Smith|        XXXXXXXXX|            PR|    9243 Old Gardens|           00725|\n",
      "|             2667|2013-07-25 00:00:...|      17|       COMPLETE|   Sun Valley|     XXXXXXXXX|         Tammy|       2667|         Smith|        XXXXXXXXX|            CA| \"8906 Rustic Mall \"|           91352|\n",
      "|             1205|2013-07-25 00:00:...|      18|         CLOSED|        Miami|     XXXXXXXXX|          Mary|       1205|        Powell|        XXXXXXXXX|            FL|9299 Quiet Pionee...|           33126|\n",
      "|             9488|2013-07-25 00:00:...|      19|PENDING_PAYMENT|      Hialeah|     XXXXXXXXX|          Mary|       9488|         Smith|        XXXXXXXXX|            FL|    9758 Foggy Range|           33012|\n",
      "|             9198|2013-07-25 00:00:...|      20|     PROCESSING|Bowling Green|     XXXXXXXXX|         David|       9198|          Kerr|        XXXXXXXXX|            KY|7312 Crystal Will...|           42101|\n",
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StorageLevel.DISK_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = order_df.join(broadcast(customer_df),order_df.order_customer_id == customer_df.customer_id).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "|order_customer_id|          order_date|order_id|   order_status|customer_city|customer_email|customer_fname|customer_id|customer_lname|customer_password|customer_state|     customer_street|customer_zipcode|\n",
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "|            11599|2013-07-25 00:00:...|       1|         CLOSED|      Hickory|     XXXXXXXXX|          Mary|      11599|        Malone|        XXXXXXXXX|            NC|8708 Indian Horse...|           28601|\n",
      "|              256|2013-07-25 00:00:...|       2|PENDING_PAYMENT|      Chicago|     XXXXXXXXX|         David|        256|     Rodriguez|        XXXXXXXXX|            IL|7605 Tawny Horse ...|           60625|\n",
      "|            12111|2013-07-25 00:00:...|       3|       COMPLETE|   Santa Cruz|     XXXXXXXXX|         Amber|      12111|        Franco|        XXXXXXXXX|            CA|8766 Clear Prairi...|           95060|\n",
      "|             8827|2013-07-25 00:00:...|       4|         CLOSED|  San Antonio|     XXXXXXXXX|         Brian|       8827|        Wilson|        XXXXXXXXX|            TX|   8396 High Corners|           78240|\n",
      "|            11318|2013-07-25 00:00:...|       5|       COMPLETE|       Caguas|     XXXXXXXXX|          Mary|      11318|         Henry|        XXXXXXXXX|            PR|3047 Silent Ember...|           00725|\n",
      "|             7130|2013-07-25 00:00:...|       6|       COMPLETE|     Brooklyn|     XXXXXXXXX|         Alice|       7130|         Smith|        XXXXXXXXX|            NY|      8852 Iron Port|           11237|\n",
      "|             4530|2013-07-25 00:00:...|       7|       COMPLETE|        Miami|     XXXXXXXXX|          Mary|       4530|         Smith|        XXXXXXXXX|            FL|1073 Green Leaf G...|           33161|\n",
      "|             2911|2013-07-25 00:00:...|       8|     PROCESSING|       Caguas|     XXXXXXXXX|          Mary|       2911|         Smith|        XXXXXXXXX|            PR|9166 Golden Necta...|           00725|\n",
      "|             5657|2013-07-25 00:00:...|       9|PENDING_PAYMENT|     Lakewood|     XXXXXXXXX|          Mary|       5657|         James|        XXXXXXXXX|            OH|  1389 Dusty Circuit|           44107|\n",
      "|             5648|2013-07-25 00:00:...|      10|PENDING_PAYMENT|      Memphis|     XXXXXXXXX|        Joshua|       5648|         Smith|        XXXXXXXXX|            TN|864 Iron Spring S...|           38111|\n",
      "|              918|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|       Caguas|     XXXXXXXXX|        Nathan|        918|         Smith|        XXXXXXXXX|            PR|    9627 Honey Trail|           00725|\n",
      "|             1837|2013-07-25 00:00:...|      12|         CLOSED|       Caguas|     XXXXXXXXX|          Mary|       1837|          Vega|        XXXXXXXXX|            PR|  4312 Bright Corner|           00725|\n",
      "|             9149|2013-07-25 00:00:...|      13|PENDING_PAYMENT|    Santa Ana|     XXXXXXXXX|        Ronald|       9149|     Whitehead|        XXXXXXXXX|            CA|6789 Round Robin ...|           92705|\n",
      "|             9842|2013-07-25 00:00:...|      14|     PROCESSING|       Caguas|     XXXXXXXXX|          Mary|       9842|         Smith|        XXXXXXXXX|            PR|454 Lazy Branch F...|           00725|\n",
      "|             2568|2013-07-25 00:00:...|      15|       COMPLETE|      Memphis|     XXXXXXXXX|         Maria|       2568|         Smith|        XXXXXXXXX|            TN|   3544 Fallen Mount|           38127|\n",
      "|             7276|2013-07-25 00:00:...|      16|PENDING_PAYMENT|       Caguas|     XXXXXXXXX|        Pamela|       7276|         Smith|        XXXXXXXXX|            PR|    9243 Old Gardens|           00725|\n",
      "|             2667|2013-07-25 00:00:...|      17|       COMPLETE|   Sun Valley|     XXXXXXXXX|         Tammy|       2667|         Smith|        XXXXXXXXX|            CA| \"8906 Rustic Mall \"|           91352|\n",
      "|             1205|2013-07-25 00:00:...|      18|         CLOSED|        Miami|     XXXXXXXXX|          Mary|       1205|        Powell|        XXXXXXXXX|            FL|9299 Quiet Pionee...|           33126|\n",
      "|             9488|2013-07-25 00:00:...|      19|PENDING_PAYMENT|      Hialeah|     XXXXXXXXX|          Mary|       9488|         Smith|        XXXXXXXXX|            FL|    9758 Foggy Range|           33012|\n",
      "|             9198|2013-07-25 00:00:...|      20|     PROCESSING|Bowling Green|     XXXXXXXXX|         David|       9198|          Kerr|        XXXXXXXXX|            KY|7312 Crystal Will...|           42101|\n",
      "+-----------------+--------------------+--------+---------------+-------------+--------------+--------------+-----------+--------------+-----------------+--------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
