{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "            builder. \\\n",
    "            master('local'). \\\n",
    "            appName(\"practice\"). \\\n",
    "            getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x28e44a75a48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, count, lit\n",
    "\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName(f'{username} - Word Count'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "lines = spark.read.text('/public/randomtextwriter/part-m-0000*'). \\\n",
    "    toDF('line')\n",
    "\n",
    "word_count = lines. \\\n",
    "    select(explode(split('line', ' ')).alias('word')). \\\n",
    "    groupBy('word'). \\\n",
    "    agg(count(lit(1)).alias('word_count'))\n",
    "\n",
    "word_count. \\\n",
    "    write. \\\n",
    "    mode('overwrite'). \\\n",
    "    csv(f'/user/{username}/word_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\Kshitij kadu\\Desktop\\sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, count, lit, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, count, lit\n",
    "\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('Word Count'). \\\n",
    "    master('local'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "lines = spark.read.text(r'C:\\Users\\Kshitij kadu\\Desktop\\sample_data\\sample.txt'). \\\n",
    "    toDF('line')\n",
    "\n",
    "word_count = lines. \\\n",
    "    select(explode(split('line', ' ')).alias('word')). \\\n",
    "    groupBy('word'). \\\n",
    "    agg(count(lit(1)).alias('word_count'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk\n",
    "df = spark.read.text('path/here').toDF('line')\n",
    "df.select( explode(split('line',' ')).alias('word') ).\\\n",
    "         groupBy('word').\\\n",
    "         agg(count(lit(1)).alias('word_count')).\\\n",
    "         orderBy(col('word_count').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|If the data are s...|\n",
      "| then databases a...|\n",
      "| ACID transaction...|\n",
      "| with the growth ...|\n",
      "|scaled more easil...|\n",
      "|reducing the obje...|\n",
      "|to allow horizont...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without toDF\n",
    "lines = spark.read.text(r'C:\\Users\\Kshitij kadu\\Desktop\\sample_data\\sample.txt')\n",
    "lines.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|line                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "|If the data are structured and some form of online transaction processing is required,                  |\n",
      "| then databases are generally used.[14] Originally mostly relational databases were used, with strong   |\n",
      "| ACID transaction correctness guarantees; most relational databases use SQL for their queries. However, |\n",
      "| with the growth of data in the 2010s, NoSQL databases have also become popular since they horizontally |\n",
      "|scaled more easily than relational databases by giving up the ACID transaction guarantees, as well as   |\n",
      "|reducing the object-relational impedance mismatch.[15] More recently, NewSQL databases — which attempt  |\n",
      "|to allow horizontal scaling while retaining ACID guarantees — have become popular                       |\n",
      "+--------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with toDF\n",
    "lines = spark.read.text(r'C:\\Users\\Kshitij kadu\\Desktop\\sample_data\\sample.txt'). \\\n",
    "    toDF('line')\n",
    "\n",
    "lines.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|split(line,  , -1)                                                                                                          |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|[If, the, data, are, structured, and, some, form, of, online, transaction, processing, is, required,]                       |\n",
      "|[, then, databases, are, generally, used.[14], Originally, mostly, relational, databases, were, used,, with, strong]        |\n",
      "|[, ACID, transaction, correctness, guarantees;, most, relational, databases, use, SQL, for, their, queries., However,]      |\n",
      "|[, with, the, growth, of, data, in, the, 2010s,, NoSQL, databases, have, also, become, popular, since, they, horizontally, ]|\n",
      "|[scaled, more, easily, than, relational, databases, by, giving, up, the, ACID, transaction, guarantees,, as, well, as, ]    |\n",
      "|[reducing, the, object-relational, impedance, mismatch.[15], More, recently,, NewSQL, databases, —, which, attempt, ]       |\n",
      "|[to, allow, horizontal, scaling, while, retaining, ACID, guarantees, —, have, become, popular]                              |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "word_count = lines. \\\n",
    "    select(split('line', ' ')).alias('word')\n",
    "\n",
    "word_count.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|word       |\n",
      "+-----------+\n",
      "|If         |\n",
      "|the        |\n",
      "|data       |\n",
      "|are        |\n",
      "|structured |\n",
      "|and        |\n",
      "|some       |\n",
      "|form       |\n",
      "|of         |\n",
      "|online     |\n",
      "|transaction|\n",
      "|processing |\n",
      "|is         |\n",
      "|required,  |\n",
      "|           |\n",
      "|then       |\n",
      "|databases  |\n",
      "|are        |\n",
      "|generally  |\n",
      "|used.[14]  |\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode\n",
    "word_count = lines. \\\n",
    "    select(explode(split('line', ' ')).alias('word'))\n",
    "word_count.show(truncate = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       word|word_count|\n",
      "+-----------+----------+\n",
      "|           |         6|\n",
      "|  databases|         6|\n",
      "|        the|         5|\n",
      "|transaction|         3|\n",
      "| relational|         3|\n",
      "|       ACID|         3|\n",
      "|       have|         2|\n",
      "|       with|         2|\n",
      "|        are|         2|\n",
      "|     become|         2|\n",
      "|       data|         2|\n",
      "|         of|         2|\n",
      "|    popular|         2|\n",
      "|          —|         2|\n",
      "|         as|         2|\n",
      "|     online|         1|\n",
      "|  retaining|         1|\n",
      "|       more|         1|\n",
      "|    scaling|         1|\n",
      "|      allow|         1|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# complete\n",
    "word_count = lines. \\\n",
    "    select(explode(split('line', ' ')).alias('word')). \\\n",
    "    groupBy('word'). \\\n",
    "    agg(count(lit(1)).alias('word_count')).orderBy(col(\"word_count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
